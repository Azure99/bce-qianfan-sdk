{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理配置自动搜索\n",
    "\n",
    "千帆平台上的模型提供了大量参数可供用户调整，而这些参数设置会直接影响到模型表现，针对这个问题，SDK 提供了推理配置自动搜索功能，可以根据目标场景自动搜索出最佳的超参数配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们需要准备一个 Evaluator，用于评估搜索的结果的好坏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qianfan.evaluation.evaluator import LocalEvaluator\n",
    "from qianfan import ChatCompletion\n",
    "from qianfan.common.prompt.prompt import Prompt\n",
    "from qianfan.utils.pydantic import Field\n",
    "\n",
    "from typing import Optional, Union, Any, Dict, List\n",
    "import re\n",
    "import json\n",
    "\n",
    "class LocalJudgeEvaluator(LocalEvaluator):\n",
    "    model: Optional[ChatCompletion] = Field(default=None, description=\"model object\")\n",
    "    metric_name: str = Field(default=\"\", description=\"metric name for evaluation\")\n",
    "    eval_prompt: Prompt = Field(\n",
    "        default=Prompt(\n",
    "            template=\"\"\"你需要扮演一个裁判的角色，对一段角色扮演的对话内容进行打分，你需要考虑这段文本中的角色沉浸度和对话文本的通畅程度。你可以根据以下规则来进行打分，你可以阐述你对打分标准的理解后再给出分数：\n",
    "\"4\":完全可以扮演提问中的角色进行对话，回答完全符合角色口吻和身份，文本流畅语句通顺\n",
    "\"3\":扮演了提问中正确的角色，回答完全符合角色口吻和身份，但文本不流畅或字数不满足要求\n",
    "\"2\":扮演了提问中正确的角色，但是部分语句不符合角色口吻和身份，文本流畅语句通顺\n",
    "\"1\":能够以角色的口吻和身份进行一部分对话，和角色设定有一定偏差，回答内容不流畅，或不满足文本字数要求\n",
    "\"0\":扮演了错误的角色，没有扮演正确的角色，角色设定和提问设定差异极大，完全不满意\n",
    "你的回答需要以json代码格式输出：\n",
    "```json\n",
    "{\"modelA\": {\"justification\": \"此处阐述对打分标准的理解\", \"score\": \"此处填写打分结果\"}}\n",
    "```\n",
    "\n",
    "现在你可以开始回答了：\n",
    "问题：{{input}}\n",
    "---\n",
    "modelA回答：{{output}}\n",
    "---\"\"\",\n",
    "            identifier=\"{{}}\",\n",
    "        ),\n",
    "        description=\"evaluation prompt\",\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def evaluate(\n",
    "        self, input: Union[str, List[Dict[str, Any]]], reference: str, output: str\n",
    "    ) -> Dict[str, Any]:\n",
    "        score = 0\n",
    "        try:\n",
    "            p, _ = self.eval_prompt.render(\n",
    "                **{\n",
    "                    \"input\": \"\\n\".join([i[\"content\"] for i in input[1:]]),\n",
    "                    \"output\": output,\n",
    "                    \"expect\": reference,\n",
    "                }\n",
    "            )\n",
    "            r = self.model.do(messages=[{\"role\": \"user\", \"content\": p}])\n",
    "            content = r[\"result\"]\n",
    "            regex = re.compile(\"\\`\\`\\`json(.*)\\`\\`\\`\", re.MULTILINE | re.DOTALL)\n",
    "\n",
    "            u = regex.findall(content)\n",
    "\n",
    "            if len(u) == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                score = float(json.loads(u[0])[\"modelA\"][\"score\"])\n",
    "        except Exception as e:\n",
    "            score = 0\n",
    "        return {self.metric_name: score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参搜索主要分为两部分：\n",
    "\n",
    "- `Suggestor`：超参搜索算法，负责从搜索空间中选取一组配置\n",
    "- `Runner`：运行器，负责根据 `Suggestor` 提供的配置运行模型并给出结果\n",
    "\n",
    "SDK 已经内置了 `Suggestor` 和 `Runner`，用户只需要提供搜索空间和待评估的数据集和评估器即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qianfan.autotuner.launcher import Launcher\n",
    "from qianfan.autotuner.suggestor import RandomSuggestor\n",
    "from qianfan.autotuner.runner import QianfanRunner\n",
    "from qianfan.autotuner.space import Uniform, Categorical\n",
    "from qianfan.dataset import Dataset\n",
    "\n",
    "context = await Launcher().run(\n",
    "    suggestor=RandomSuggestor(\n",
    "        search_space = {\n",
    "            \"temperature\": Uniform(0.01, 0.99),  # 设定temperature的范围\n",
    "            \"model\": Categorical([\"ERNIE-Speed\"]),  # 设定model的取值范围\n",
    "        },\n",
    "        cost_budget=0.001,  # 设定整个流程的预算\n",
    "    ),\n",
    "    runner=QianfanRunner(\n",
    "        dataset=Dataset.load(\n",
    "            data_file=\"./example.jsonl\",\n",
    "            organize_data_as_group=False,\n",
    "            input_columns=[\"prompt\"],\n",
    "            reference_column=\"response\",\n",
    "        ),\n",
    "        evaluator=LocalJudgeEvaluator(\n",
    "            model=ChatCompletion(model=\"ERNIE-Bot-4\"), metric_name=\"accuracy\"\n",
    "        ),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回的结果是一个 `Context` 对象，其中包含了整个搜索过程的所有上下文信息，例如可以通过如下方式获得搜索的最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': 0.49294604892967614, 'model': 'ERNIE-Speed'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以获取某一轮某一组配置的评估结果等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 3.1,\n",
       " 'avg_prompt_tokens': 648.3,\n",
       " 'avg_completion_tokens': 201.3,\n",
       " 'avg_total_tokens': 849.6,\n",
       " 'avg_req_latency': 4.48412966793403,\n",
       " 'avg_tokens_per_second': 189.46820518493962,\n",
       " 'avg_cost': 0.0042036,\n",
       " 'total_cost': 0.042036000000000004}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.history[0][0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
